{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting New York Times \"Editor's Selection\" comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "\n",
    "The following notebook has the goal to predict the \"Editor's Selection\" comments of the open articles from the [New York Times](https://www.nytimes.com/) webpage.\n",
    "\n",
    "These are the steps to achieve this goal:\n",
    "- **Import data**\n",
    "- **Pre-processing features**\n",
    "- **Processing comments texts**\n",
    "- **Modeling and testing**\n",
    "- **Discussing results**\n",
    "\n",
    "The imported dataset contains data from January 2017 until May 2017 and from January 2018 until May 2018, related to articles and comments from NY Times. After importing, some features are pre-selected to be used in the model. The features are treated and some new features are created. The *editorsSelection* represents if the comment is an \"Editor's Selection\" or not, and will be the target.\n",
    "\n",
    "The feature **commentBody** represents the comment itself. I separate it and process the text using NLP techniques. I do **Count Vectorization**, **Stemming** and **TF-IDF** to vectorize and prepare the comments for use in the model.\n",
    "\n",
    "For classification, the **SVM** algorithm is the chosen one. It will be evaluated using three measures: **Accuracy**, **AUROC**, and **F1-Score**.\n",
    "\n",
    "After that, the SVM will be reparameterized with **Grid Search**.\n",
    "\n",
    "Finally, the results will be discussed and some future works will be recommended.\n",
    "\n",
    ">Some codes and ideas were inspired by [Aashita Kesarwani Predicting NYT's pick notebook](https://www.kaggle.com/aashita/predicting-nyt-s-pick/notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re, string\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from scipy.sparse import hstack\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two kinds of datasets: Articles Dataset and Comments Dataset.\n",
    "\n",
    "The Articles dataset contains more than 9000 articles and 16 features. It represents the articles headers, with information like date of publication (pubDate) and category (newDesk).\n",
    "\n",
    "The Comments dataset contains more than 2 million comments and 34 features. This dataset contains the comment feature (commentBody) and some information about the comment, i.e. comment date of publication (approveDate). Also, it contains the target feature: **editorsSelection**.\n",
    "\n",
    "Here is the feature relation:\n",
    "\n",
    "|\tArticles Dataset\t\t|\tComments Dataset   |\n",
    "|-----------------------|---------------------------|\n",
    "|\tabstract\t\t\t|\tapproveDate\t\t\t\t|\n",
    "|\tarticleID\t\t\t|\tarticleID\t\t\t\t|\n",
    "|\tarticleWordCount\t|\tarticleWordCount\t\t|\n",
    "|\tbyline\t\t\t\t|\tcommentBody\t\t\t\t|\n",
    "|\twebURL\t\t\t\t|\tcommentID\t\t\t\t|\n",
    "|\ttypeOfMaterial\t\t|\tcommentSequence\t\t\t|\n",
    "|\tsource\t\t\t\t|\tcommentTitle\t\t\t|\n",
    "|\tsnippet\t\t\t\t|\tcommentType\t\t\t\t|\n",
    "|\tsectionName\t\t\t|\tcreateDate\t\t\t\t|\n",
    "|\tpubDate\t\t\t\t|\tdepth\t\t\t\t\t|\n",
    "|\tprintPage\t\t\t|\teditorsSelection\t\t|\n",
    "|\tdocumentType\t\t|\tinReplyTo\t\t\t\t|\n",
    "|\theadline\t\t\t|\tnewDesk\t\t\t\t\t|\n",
    "|\tkeywords\t\t\t|\tparentID\t\t\t\t|\n",
    "|\tmultimedia\t\t\t|\tparentUserDisplayName\t|\n",
    "|\tnewDesk\t\t\t\t|\tpermID\t\t\t\t\t|\n",
    "|\t\t\t\t\t\t|\tpicURL\t\t\t\t\t|\n",
    "|\t\t\t\t\t\t|\tprintPage\t\t\t\t|\n",
    "|\t\t\t\t\t\t|\trecommendations\t\t\t|\n",
    "|\t\t\t\t\t\t|\trecommendedFlag\t\t\t|\n",
    "|\t\t\t\t\t\t|\treplyCount\t\t\t\t|\n",
    "|\t\t\t\t\t\t|\treportAbuseFlag\t\t\t|\n",
    "|\t \t\t\t\t\t|\tsectionName\t\t\t\t|\n",
    "|\t\t\t\t\t\t|\tsharing\t\t\t\t\t|\n",
    "|\t\t\t\t\t\t|\tstatus\t\t\t\t\t|\n",
    "|\t\t\t\t\t\t|\ttimespeople\t\t\t\t|\n",
    "|\t\t\t\t\t\t|\ttrusted\t\t\t\t\t|\n",
    "|\t\t\t\t\t\t|\ttypeOfMaterial\t\t\t|\n",
    "|\t\t\t\t\t\t|\tupdateDate\t\t\t\t|\n",
    "|\t\t\t\t\t\t|\tuserDisplayName\t\t\t|\n",
    "|\t\t\t\t\t\t|\tuserID\t\t\t\t\t|\n",
    "|\t\t\t\t\t\t|\tuserLocation\t\t\t|\n",
    "|\t\t\t\t\t\t|\tuserTitle\t\t\t\t|\n",
    "|\t\t\t\t\t\t|\tuserURL\t\t\t\t\t|\n",
    "\n",
    "For now, some features will be *excluded* from our study. Some will be removed due to their nature of non-relation with our problem.\n",
    "\n",
    "Here are the chosen features for now:\n",
    "\n",
    "|\tArticles festures\t\t|\tComments features\t|\n",
    "|---------------------------|---------------------------|\n",
    "|\tarticleID\t\t\t\t|\tarticleID\t\t\t\t|\n",
    "|\tarticleWordCount\t\t|\tcreateDate\t\t\t\t|\n",
    "|\tnewDesk\t\t\t\t\t|\tapproveDate\t\t\t\t|\n",
    "|\ttypeOfMaterial\t\t\t|\tcommentBody\t\t\t\t|\n",
    "|\tpubDate \t\t\t\t|\trecommendations\t\t\t|\n",
    "|\t     \t\t\t\t\t|\treplyCount\t\t\t\t|\n",
    "|\t\t\t\t\t\t\t|\teditorsSelection\t\t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_columns = ['articleID', 'articleWordCount', 'newDesk', 'typeOfMaterial', 'pubDate']\n",
    "com_columns = ['articleID', 'createDate', 'approveDate', 'commentBody', 'recommendations', 'replyCount','editorsSelection']\n",
    "\n",
    "df_art_jan17 = pd.read_csv('nyt-comments/ArticlesJan2017.csv', usecols=art_columns)\n",
    "df_com_jan17 = pd.read_csv('nyt-comments/CommentsJan2017.csv', usecols=com_columns)\n",
    "df_art_fev17 = pd.read_csv('nyt-comments/ArticlesFeb2017.csv', usecols=art_columns)\n",
    "df_com_fev17 = pd.read_csv('nyt-comments/CommentsFeb2017.csv', usecols=com_columns)\n",
    "df_art_mar17 = pd.read_csv('nyt-comments/ArticlesMarch2017.csv', usecols=art_columns)\n",
    "df_com_mar17 = pd.read_csv('nyt-comments/CommentsMarch2017.csv', usecols=com_columns)\n",
    "df_art_apr17 = pd.read_csv('nyt-comments/ArticlesApril2017.csv', usecols=art_columns)\n",
    "df_com_apr17 = pd.read_csv('nyt-comments/CommentsApril2017.csv', usecols=com_columns)\n",
    "df_art_may17 = pd.read_csv('nyt-comments/ArticlesMay2017.csv', usecols=art_columns)\n",
    "df_com_may17 = pd.read_csv('nyt-comments/CommentsMay2017.csv', usecols=com_columns)\n",
    "df_art_jan18 = pd.read_csv('nyt-comments/ArticlesJan2018.csv', usecols=art_columns)\n",
    "df_com_jan18 = pd.read_csv('nyt-comments/CommentsJan2018.csv', usecols=com_columns)\n",
    "df_art_fev18 = pd.read_csv('nyt-comments/ArticlesFeb2018.csv', usecols=art_columns)\n",
    "df_com_fev18 = pd.read_csv('nyt-comments/CommentsFeb2018.csv', usecols=com_columns)\n",
    "df_art_mar18 = pd.read_csv('nyt-comments/ArticlesMarch2018.csv', usecols=art_columns)\n",
    "df_com_mar18 = pd.read_csv('nyt-comments/CommentsMarch2018.csv', usecols=com_columns)\n",
    "df_art_apr18 = pd.read_csv('nyt-comments/ArticlesApril2018.csv', usecols=art_columns)\n",
    "df_com_apr18 = pd.read_csv('nyt-comments/CommentsApril2018.csv', usecols=com_columns)\n",
    "\n",
    "comments = [df_com_jan17, df_com_fev17, df_com_mar17, df_com_apr17, df_com_may17, df_com_jan18, df_com_fev18, df_com_mar18, df_com_apr18]\n",
    "df_comments = pd.concat(comments)\n",
    "articles = [df_art_jan17, df_art_fev17, df_art_mar17, df_art_apr17, df_art_may17, df_art_jan18, df_art_fev18, df_art_mar18, df_art_apr18]\n",
    "df_articles = pd.concat(articles)\n",
    "\n",
    "df = pd.merge(df_articles, df_comments, on='articleID', how='inner') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments feature\n",
    "\n",
    "Most of the comments of NY Times naturally are written in English. However, since the comments are opened for anyone, consequently we expect to find errors and unsupported characters (from different languages). For example, HTML tags and Japanese characters.\n",
    "\n",
    "Since the nature of an \"Editor's Selection\" comment is to be well written and containing a relevant opinion about the subject, we must treat the inconveniences of the **commentBody** feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing tags and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(text):\n",
    "    TAG_RE = re.compile(r'<[^>]+>')\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]',' ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.commentBody = df.commentBody.apply(lambda x: remove_tags(x))\n",
    "df.commentBody = df.commentBody.apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing wrong coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.commentBody = df.commentBody.apply(lambda x: str(x.encode('ascii', 'ignore')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating english words\n",
    "\n",
    "Using Name Entity Recognition (NER) and some English dictionary, it is possible to maintain only English words in comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1492.6859822273254\n"
     ]
    }
   ],
   "source": [
    "#Creating Name/Entity/Place dictionary\n",
    "def NER(df):\n",
    "    continuous_chunk = []\n",
    "    for index, row in df.iterrows():\n",
    "        chunked = ne_chunk(pos_tag(word_tokenize(row['commentBody'])))\n",
    "        prev = None\n",
    "        current_chunk = []\n",
    "        for i in chunked:\n",
    "            if type(i) == Tree:\n",
    "                current_chunk.append(\" \".join([token for token, pos in i.leaves()]))\n",
    "            elif current_chunk:\n",
    "                named_entity = \" \".join(current_chunk)\n",
    "                if named_entity not in continuous_chunk:\n",
    "                    continuous_chunk.append(named_entity)\n",
    "                    current_chunk = []\n",
    "                else:\n",
    "                    continue\n",
    "    return set(continuous_chunk)\n",
    "\n",
    "start_time = time.time()\n",
    "#Using only NER extracted from comments selected as \"Editor's Selection\" to reduce the dictionary\n",
    "people_words = NER(df[df['editorsSelection'] == 1])\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating English Dictionary using NLTK package\n",
    "words = set(nltk.corpus.words.words() + list(nltk.corpus.wordnet.words()) + list(people_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326.3583779335022\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    return \" \".join(w for w in nltk.wordpunct_tokenize(text) if w in words or w.lower() in words or (nltk.corpus.wordnet.morphy(w.lower()) is not None and nltk.corpus.wordnet.morphy(w.lower()).lower() in words))\n",
    "\n",
    "start_time = time.time()\n",
    "df.commentBody = df.commentBody.apply(lambda x: clean_text(x)) \n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating feature variations\n",
    "\n",
    "The data features won't be useful in their original conditions. It is necessary to quantify them.\n",
    "\n",
    "In this case, it will be created two new features: **commentApprovalLength**, which represents the waiting time for the comment to be approved; and **commentPubLength**, which is the time between the article publication and the comment publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['commentApprovalLength'] = df.apply(lambda row: (dt.datetime.fromtimestamp(int(row['approveDate'])) - dt.datetime.fromtimestamp(int(row['createDate']))).total_seconds(), axis=1)\n",
    "df['commentPubLength'] = df.apply(lambda row: (dt.datetime.fromtimestamp(int(row['approveDate'])) - dt.datetime.strptime(row['pubDate'], '%Y-%m-%d %H:%M:%S')).total_seconds(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, it is now possible to count the number of words of the treated commentBody feature creating a new column called **commentWordCount**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['commentWordCount'] = df.apply(lambda row: sum(Counter(row['commentBody'].split()).values()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning unused features\n",
    "df.drop(columns=['approveDate', 'createDate', 'articleID', 'pubDate'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantifying categorical features\n",
    "\n",
    "The categorical features should be transformed into numerical features to help the classifier to not misinterpret. It will be created new columns to represent the categories in numbers (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=[\"newDesk\", \"typeOfMaterial\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing numerical features\n",
    "\n",
    "The numerical features should be normalized to avoid wrong weighted classification. The MinMaxScaler() will be used for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#Array with numerical features\n",
    "np_numbers = df[['articleWordCount', 'recommendations', 'replyCount', 'commentWordCount', 'commentApprovalLength', 'commentPubLength']].values.astype(float)\n",
    "\n",
    "#Normalizing\n",
    "np_scaled = min_max_scaler.fit_transform(np_numbers)\n",
    "df_normalized = pd.DataFrame(np_scaled)\n",
    "#Renaming columns\n",
    "df_normalized.columns = ['articleWordCount', 'recommendations', 'replyCount', 'commentWordCount', 'commentApprovalLength', 'commentPubLength']\n",
    "\n",
    "#Joining new dataframe\n",
    "cols = [i for i in df.columns.values if i not in list(['articleWordCount', 'recommendations', 'replyCount', 'commentWordCount','commentApprovalLength','commentPubLength'])]\n",
    "df_normalized = df_normalized.join(df[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>commentWordCount</th>\n",
       "      <th>commentApprovalLength</th>\n",
       "      <th>commentPubLength</th>\n",
       "      <th>commentBody</th>\n",
       "      <th>editorsSelection</th>\n",
       "      <th>newDesk_Arts&amp;Leisure</th>\n",
       "      <th>newDesk_Automobiles</th>\n",
       "      <th>...</th>\n",
       "      <th>typeOfMaterial_Editorial</th>\n",
       "      <th>typeOfMaterial_Interview</th>\n",
       "      <th>typeOfMaterial_Letter</th>\n",
       "      <th>typeOfMaterial_News</th>\n",
       "      <th>typeOfMaterial_News Analysis</th>\n",
       "      <th>typeOfMaterial_Obituary (Obit)</th>\n",
       "      <th>typeOfMaterial_Op-Ed</th>\n",
       "      <th>typeOfMaterial_Question</th>\n",
       "      <th>typeOfMaterial_Review</th>\n",
       "      <th>typeOfMaterial_briefing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080429</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.160804</td>\n",
       "      <td>0.291866</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>b For all you Americans out there still rejoic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.080429</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.160804</td>\n",
       "      <td>0.143541</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.005402</td>\n",
       "      <td>b Obamas policies may prove to be the least of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   articleWordCount  recommendations  replyCount  commentWordCount  \\\n",
       "0          0.080429         0.000477    0.160804          0.291866   \n",
       "1          0.080429         0.000286    0.160804          0.143541   \n",
       "\n",
       "   commentApprovalLength  commentPubLength  \\\n",
       "0               0.001730          0.005408   \n",
       "1               0.002221          0.005402   \n",
       "\n",
       "                                         commentBody  editorsSelection  \\\n",
       "0  b For all you Americans out there still rejoic...                 0   \n",
       "1  b Obamas policies may prove to be the least of...                 0   \n",
       "\n",
       "   newDesk_Arts&Leisure  newDesk_Automobiles           ...             \\\n",
       "0                     0                    0           ...              \n",
       "1                     0                    0           ...              \n",
       "\n",
       "   typeOfMaterial_Editorial  typeOfMaterial_Interview  typeOfMaterial_Letter  \\\n",
       "0                         0                         0                      0   \n",
       "1                         0                         0                      0   \n",
       "\n",
       "   typeOfMaterial_News  typeOfMaterial_News Analysis  \\\n",
       "0                    1                             0   \n",
       "1                    1                             0   \n",
       "\n",
       "   typeOfMaterial_Obituary (Obit)  typeOfMaterial_Op-Ed  \\\n",
       "0                               0                     0   \n",
       "1                               0                     0   \n",
       "\n",
       "   typeOfMaterial_Question  typeOfMaterial_Review  typeOfMaterial_briefing  \n",
       "0                        0                      0                        0  \n",
       "1                        0                      0                        0  \n",
       "\n",
       "[2 rows x 66 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking how the features are now\n",
    "df_normalized.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how the targed feature **editorsSelection** is balanced in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9107573251608228\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.value_counts(df_normalized['editorsSelection']).plot.pie(figsize = (5,5))\n",
    "print((float(pd.value_counts(df_normalized['editorsSelection'])[1])/float(pd.value_counts(df_normalized['editorsSelection']).sum())) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is notable the unbalanced dataset. The editorsSelection class = 1 represents **1.91%** of the entire dataset. To work with this class, it is necessary to downsample the editorsSelection class = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Returns the balanced class using the percentage that is needed to maintain in the class with less occurrence.\n",
    "For example, if we need the class 1 (minority) to represents 30% of the entire dataset, percent = 0.3. \n",
    "The class 0 (majority) will have samples removed randomly until it represents 70% of the entire dataset.\n",
    "'''\n",
    "def downSampling(sample, col_class, percent):\n",
    "    #Finding the majority and minority class\n",
    "    counts = sample[col_class].value_counts().to_dict()\n",
    "    max_label = max(counts.keys(), key=(lambda k: counts[k]))\n",
    "    min_label = min(counts.keys(), key=(lambda k: counts[k]))\n",
    "    #Separating class samples\n",
    "    sample_max = sample[sample[col_class] == max_label]\n",
    "    sample_min = sample[sample[col_class] == min_label]\n",
    "    #Finding the actual ratio between classes\n",
    "    actual_ratio = float(min(counts.values()))/float(sum(counts.values()))\n",
    "    if(actual_ratio >= percent):\n",
    "        return sample\n",
    "    #Calculating the number of necessary samples to be excluded\n",
    "    desired_samples = int(float(min(counts.values()) - (percent * min(counts.values()))) / float(percent))\n",
    "    #Resampling dataset\n",
    "    sample_max_downsampled = resample(sample_max, replace=False, n_samples=desired_samples, random_state=100)\n",
    "    #Combining samples\n",
    "    sample_downsampled = pd.concat([sample_max_downsampled, sample_min])\n",
    "    return sample_downsampled\n",
    "\n",
    "#It was chosen the 1:4 (25%) ratio for downsampling\n",
    "df_normalized_balanced = downSampling(df_normalized, 'editorsSelection', 0.25)\n",
    "pd.value_counts(df_normalized_balanced['editorsSelection']).plot.pie(figsize = (5,5))\n",
    "print((float(pd.value_counts(df_normalized_balanced['editorsSelection'])[1])/float(pd.value_counts(df_normalized_balanced['editorsSelection']).sum())) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">It was chosen the value of 25% to compare to [Aashita Kesarwani Predicting NYT's pick notebook](https://www.kaggle.com/aashita/predicting-nyt-s-pick/notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the editorsSelection class = 1 is balanced to represents **25%** of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP - Working with comments\n",
    "\n",
    "Now we use NLP techniques to transform the comments text into a feature vector, to use later in classification.\n",
    "\n",
    "#### Count Vectorizer e Stemming\n",
    "\n",
    "We will use Count Vectorizer to transform text into a count vector with the words frequency. Also, we use Stemming to reduce words to the root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165944, 31995)\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "    \n",
    "stemmed_count_vect = StemmedCountVectorizer(stop_words='english', decode_error='ignore')\n",
    "counts = stemmed_count_vect.fit_transform(df_normalized_balanced['commentBody'].values.astype('U'))\n",
    "\n",
    "print(counts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF\n",
    "To reduce the weight of the counting, it is needed to normalize frequency with TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165944, 31995)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf = tfidf_transformer.fit_transform(counts)\n",
    "\n",
    "print(tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What we have so far**: cleaned and treated features, extra features and comment texts vectorized.\n",
    "\n",
    "Now we build our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let's separate the target feature from the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_normalized_balanced[['editorsSelection']]\n",
    "X = df_normalized_balanced.drop(['editorsSelection', 'commentBody'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification algorithm chosen is SVM with linear kernel (**SGDClassifier**).\n",
    "\n",
    "The chosen metrics to measure the model performance will be **Acurracy**, **AUROC**, and **F1-Score**.\n",
    "\n",
    "For training and validation, the dataset will be split into three parts: **80%/20%**, **70%/30%** e **60%/40%** (Training/Testing). After that, we calculate the mean of the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_test, predicted):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, predicted, pos_label=1)\n",
    "    roc = auc(fpr, tpr)\n",
    "    f1 = f1_score(y_test, predicted, average='binary')\n",
    "    ac = np.mean(predicted == y_test)\n",
    "    return roc, f1, ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(clf, X_train, y_train, X_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted = clf.predict(X_test)\n",
    "    return predicted\n",
    "\n",
    "def results_train_test(clf, X, y):\n",
    "\n",
    "    X_train_80, X_test_20, y_train_80, y_test_20 = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "    X_train_70, X_test_30, y_train_70, y_test_30 = train_test_split(X, y, test_size=0.3, random_state=100)\n",
    "    X_train_60, X_test_40, y_train_60, y_test_40 = train_test_split(X, y, test_size=0.4, random_state=100)\n",
    "\n",
    "    pred_20 = train_predict(clf, X_train_80, y_train_80, X_test_20)\n",
    "    pred_30 = train_predict(clf, X_train_70, y_train_70, X_test_30)\n",
    "    pred_40 = train_predict(clf, X_train_60, y_train_60, X_test_40)\n",
    "\n",
    "    roc20, f120, acc20 = get_metrics(y_test_20, pred_20)\n",
    "    roc30, f130, acc30 = get_metrics(y_test_30, pred_30)\n",
    "    roc40, f140, acc40 = get_metrics(y_test_40, pred_40)\n",
    "    mean_roc = (roc20 + roc30 + roc40) / 3\n",
    "    mean_acc = (acc20 + acc30 + acc40) / 3\n",
    "    mean_f1 = (f120 + f130 + f140) / 3\n",
    "    print('Mean Accuracy: {0:0.2f}'.format(mean_acc))\n",
    "    print('Mean AUROC: {0:0.2f}'.format(mean_roc))\n",
    "    print('Mean F1-Score: {0:0.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the full feature vector, joining the TF-IDF output and the others features.\n",
    "\n",
    ">Hstack is used to avoid memory overflow when adding the TF-IDF features to dataframe. Also, we will work with sparse matrices from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165944, 32059)\n"
     ]
    }
   ],
   "source": [
    "cols = [i for i in df_normalized_balanced.columns.values if i not in list(['editorsSelection','commentBody', 'articleWordCount'])]\n",
    "\n",
    "features_vector = hstack((tfidf,np.array(X['articleWordCount'])[:,None]))\n",
    "for i in cols:\n",
    "    features_vector = hstack((features_vector,np.array(X[i])[:,None]))\n",
    "print(features_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test the **SVM**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating SVM class with arbitrary parameters\n",
    "svm_clf = linear_model.SGDClassifier(loss='hinge', max_iter=5, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.80\n",
      "Mean AUROC: 0.61\n",
      "Mean F1-Score: 0.36\n"
     ]
    }
   ],
   "source": [
    "results_train_test(svm_clf, features_vector, y.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize the SVM performance, we are going to use **Grid Search**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search\n",
    "\n",
    "To improve the SVM parameterization, we put some parameters to GridSearch finds the optimal configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('clf', SGDClassifier())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__alpha': (0.0001, 0.00001, 0.000001, 0.0000001),\n",
    "    'clf__epsilon': (0.1, 0.01, 0.001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    'clf__max_iter': (5, 10, 15, 20),\n",
    "    'clf__class_weight': ('balanced', {0:.1, 1:.2}, {0:.1, 1:.3}, {0:.1, 1:.4})\n",
    "}\n",
    "grid = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 384 candidates, totalling 1152 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   47.6s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1152 out of 1152 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('clf', SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__alpha': (0.0001, 1e-05, 1e-06, 1e-07), 'clf__epsilon': (0.1, 0.01, 0.001), 'clf__penalty': ('l2', 'elasticnet'), 'clf__max_iter': (5, 10, 15, 20), 'clf__class_weight': ('balanced', {0: 0.1, 1: 0.2}, {0: 0.1, 1: 0.3}, {0: 0.1, 1: 0.4})},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For GridSearch we will use the training/testing ratio of 70%/30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_vector, y.values.ravel(), test_size=0.3, random_state=100)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      "\tclf__alpha: 1e-06\n",
      "\tclf__class_weight: {0: 0.1, 1: 0.2}\n",
      "\tclf__epsilon: 0.01\n",
      "\tclf__max_iter: 20\n",
      "\tclf__penalty: 'elasticnet'\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\")\n",
    "best_parameters = grid.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the best parameters, it is possible to improve SVM performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.85\n",
      "Mean AUROC: 0.80\n",
      "Mean F1-Score: 0.70\n"
     ]
    }
   ],
   "source": [
    "optimal_svm_clf = linear_model.SGDClassifier(loss='hinge', penalty='elasticnet', alpha=1e-06, epsilon=0.01, max_iter=20, class_weight={0: 0.1, 1: 0.2}, random_state=100)\n",
    "results_train_test(optimal_svm_clf, features_vector, y.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM (first results)\n",
    "\n",
    "|\t -\t\t|\tSVM (Raw)\t|\n",
    "|---------------------------|---------------------------|\n",
    "|\tMean Accuracy\t\t\t\t|\t0.80\t\t\t\t|\n",
    "| Mean AUROC | 0.61|\n",
    "| Mean F1-Score | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first results show us how hard is to the classifier to infer the class = 1 (\"Editor's Selection\") due to the class balance. Even reducing the unbalanced class from our first dataset, it is still hard to classify with not much knowledge of the parameters.\n",
    "\n",
    "#### SVM (Grid Search)\n",
    "| - |\tSVM (Grid Search)\t\t\t|\n",
    "|-|-----------------------|\n",
    "| Mean Accuracy\t\t\t| 0.85 |\n",
    "| Mean AUROC  | 0.80 |\n",
    "| Mean F1-Score\t\t\t| 0.70 |\n",
    "\n",
    "The results now are way better. Improving the f1-score in Grid Search helped the SVM to penalise misclassification of the class = 1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future work suggestions\n",
    "\n",
    "There are some ways to improve the model.\n",
    "\n",
    "- The ignored features from the beginning may be used to achieve new insights into the dataset.\n",
    "- Feature selection may help to improve the model generalization and avoid overfitting. Maybe XGBoost could be a good option to reduce dimensionality.\n",
    "- SVM may be improved using another kernel. Linear kernel is good in performance, but there are others kernels can generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
